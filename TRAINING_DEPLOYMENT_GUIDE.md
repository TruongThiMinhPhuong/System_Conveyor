# ğŸš€ HÆ°á»›ng Dáº«n Train Model TrÃªn Laptop vÃ  Triá»ƒn Khai LÃªn Raspberry Pi 4

**Training on Laptop (GPU) â†’ Optimize â†’ Deploy to Raspberry Pi 4 (8GB RAM)**

## ğŸ“‹ Tá»•ng Quan Quy TrÃ¬nh / Workflow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LAPTOP (GPU)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Thu tháº­p data (Data Collection)                                 â”‚
â”‚     â””â”€â†’ dataset/raw_images/                                         â”‚
â”‚                                                                      â”‚
â”‚  2. GÃ¡n nhÃ£n (Labeling)                                             â”‚
â”‚     â””â”€â†’ dataset/train/, dataset/valid/, dataset/test/              â”‚
â”‚                                                                      â”‚
â”‚  3. Train model (Training)                                          â”‚
â”‚     â”œâ”€â†’ YOLOv8: ai_models/yolo_best.pt (object detection)          â”‚
â”‚     â””â”€â†’ MobileNetV2: ai_models/mobilenet_model.h5 (classification) â”‚
â”‚                                                                      â”‚
â”‚  4. Tá»‘i Æ°u model (Optimization)                                     â”‚
â”‚     â”œâ”€â†’ Resize áº£nh (224x224 â†’ 96x96 hoáº·c 128x128)                 â”‚
â”‚     â”œâ”€â†’ TFLite INT8 Quantization                                   â”‚
â”‚     â””â”€â†’ ai_models/mobilenet_model_int8.tflite                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                        COPY MODEL
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RASPBERRY PI 4 (8GB RAM)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  5. Cháº¡y suy luáº­n real-time (Inference on CPU)                      â”‚
â”‚     â”œâ”€â†’ YOLOv8 (ncnn format hoáº·c .pt nháº¹)                          â”‚
â”‚     â””â”€â†’ MobileNetV2 INT8 TFLite                                     â”‚
â”‚                                                                      â”‚
â”‚  6. Káº¿t quáº£ (Results)                                               â”‚
â”‚     â”œâ”€â†’ Äá»™ chÃ­nh xÃ¡c: >85%                                          â”‚
â”‚     â”œâ”€â†’ FPS: 15-25 (tÃ¹y Ä‘á»™ phá»©c táº¡p)                               â”‚
â”‚     â””â”€â†’ Há»‡ thá»‘ng phÃ¢n loáº¡i trÃ¡i cÃ¢y real-time                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ BÆ¯á»šC 1: Chuáº©n Bá»‹ MÃ´i TrÆ°á»ng (Setup Environment)

### TrÃªn Laptop (Windows/Linux vá»›i GPU)

```powershell
# 1. Clone repository
git clone https://github.com/TruongThiMinhPhuong/System_Conveyor.git
cd System_Conveyor

# 2. Táº¡o mÃ´i trÆ°á»ng áº£o (Virtual Environment)
python -m venv venv
.\venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 3. CÃ i Ä‘áº·t dependencies cho training
pip install -r requirements-pc.txt

# requirements-pc.txt bao gá»“m:
# - tensorflow>=2.10.0 (há»— trá»£ GPU)
# - opencv-python>=4.8.0
# - ultralytics>=8.0.0 (YOLOv8)
# - numpy, matplotlib, scikit-learn
```

### Kiá»ƒm Tra GPU

```python
# test_gpu.py
import tensorflow as tf
print("TensorFlow version:", tf.__version__)
print("GPU available:", tf.config.list_physical_devices('GPU'))
print("CUDA:", tf.test.is_built_with_cuda())
```

---

## ğŸ—‚ï¸ BÆ¯á»šC 2: Thu Tháº­p vÃ  GÃ¡n NhÃ£n Dá»¯ Liá»‡u (Data Collection & Labeling)

### 2.1 Thu Tháº­p áº¢nh

**Sá»­ dá»¥ng script cÃ³ sáºµn (vá»›i webcam/camera):**

```bash
python data_collection_script.py
```

Script nÃ y sáº½:
- Má»Ÿ camera vÃ  hiá»ƒn thá»‹ preview
- Nháº¥n `SPACE` Ä‘á»ƒ chá»¥p áº£nh
- áº¢nh Ä‘Æ°á»£c lÆ°u vÃ o `raw_images/`
- Nháº¥n `q` Ä‘á»ƒ thoÃ¡t

**Hoáº·c thu tháº­p áº£nh thá»§ cÃ´ng:**
- Chá»¥p Ã­t nháº¥t **500-1000 áº£nh** cho má»—i loáº¡i trÃ¡i cÃ¢y
- Äa dáº¡ng gÃ³c Ä‘á»™, Ã¡nh sÃ¡ng, ná»n
- Äáº·t trong thÆ° má»¥c `raw_images/apple/`, `raw_images/orange/`, v.v.

### 2.2 GÃ¡n NhÃ£n (Labeling)

#### Cho YOLOv8 (Object Detection):

1. **Sá»­ dá»¥ng LabelImg hoáº·c Roboflow:**
   ```bash
   pip install labelImg
   labelImg
   ```

2. **Format YOLO:**
   - Má»—i áº£nh cÃ³ 1 file `.txt` tÆ°Æ¡ng á»©ng
   - Format: `class_id center_x center_y width height` (normalized 0-1)
   - VÃ­ dá»¥: `0 0.5 0.5 0.8 0.8`

3. **Cáº¥u trÃºc thÆ° má»¥c:**
   ```
   dataset/
   â”œâ”€â”€ train/
   â”‚   â”œâ”€â”€ images/
   â”‚   â””â”€â”€ labels/
   â”œâ”€â”€ valid/
   â”‚   â”œâ”€â”€ images/
   â”‚   â””â”€â”€ labels/
   â””â”€â”€ data.yaml
   ```

4. **File data.yaml:**
   ```yaml
   train: dataset/train/images
   val: dataset/valid/images
   nc: 2
   names: ['apple', 'orange']
   ```

#### Cho MobileNetV2 (Classification):

1. **Cáº¥u trÃºc thÆ° má»¥c Ä‘Æ¡n giáº£n hÆ¡n:**
   ```
   dataset/
   â”œâ”€â”€ train/
   â”‚   â”œâ”€â”€ fresh/
   â”‚   â”‚   â”œâ”€â”€ img1.jpg
   â”‚   â”‚   â””â”€â”€ img2.jpg
   â”‚   â””â”€â”€ spoiled/
   â”‚       â”œâ”€â”€ img1.jpg
   â”‚       â””â”€â”€ img2.jpg
   â”œâ”€â”€ valid/
   â”‚   â”œâ”€â”€ fresh/
   â”‚   â””â”€â”€ spoiled/
   â””â”€â”€ test/
       â”œâ”€â”€ fresh/
       â””â”€â”€ spoiled/
   ```

2. **Kiá»ƒm tra cháº¥t lÆ°á»£ng dataset:**
   ```bash
   python dataset_quality_checker.py
   ```

---

## ğŸ‹ï¸ BÆ¯á»šC 3: Train Model TrÃªn Laptop (Training)

### 3.1 Train YOLOv8 (Object Detection)

```bash
# Quick training script
python quick_train.py
```

**Hoáº·c train thá»§ cÃ´ng:**

```python
# train_yolo.py
from ultralytics import YOLO

# Load pretrained model
model = YOLO('yolov8n.pt')  # nano version (nháº¹ nháº¥t)

# Train
results = model.train(
    data='dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,  # GPU
    project='training',
    name='yolo_fruit_detection',
    patience=20,
    save=True
)

# Model saved to: training/yolo_fruit_detection/weights/best.pt
```

**ÄÃ¡nh giÃ¡ model:**
```python
# Validate
metrics = model.val()
print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
```

### 3.2 Train MobileNetV2 (Classification)

**Script cÃ³ sáºµn:**
```bash
python retrain_model.py
```

**Hoáº·c sá»­ dá»¥ng Google Colab (khuyáº¿n nghá»‹):**

1. Upload `Train_MobileNet_Colab.ipynb` lÃªn Google Colab
2. NÃ©n folder dataset: `dataset.zip`
3. Upload lÃªn Colab hoáº·c Google Drive
4. Cháº¡y notebook (sá»­ dá»¥ng GPU T4 miá»…n phÃ­)
5. Download model Ä‘Ã£ train: `mobilenet_model.h5`

**Hoáº·c train thá»§ cÃ´ng:**

```python
# train_mobilenet.py
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Hyperparameters
IMG_SIZE = 224  # MobileNetV2 standard
BATCH_SIZE = 32
EPOCHS = 50

# Data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2,
    fill_mode='nearest'
)

valid_datagen = ImageDataGenerator(rescale=1./255)

# Load data
train_generator = train_datagen.flow_from_directory(
    'dataset/train',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

valid_generator = valid_datagen.flow_from_directory(
    'dataset/valid',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

# Build model
base_model = MobileNetV2(
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    include_top=False,
    weights='imagenet'
)

# Freeze base layers
base_model.trainable = False

# Add custom layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(2, activation='softmax')(x)  # 2 classes: fresh, spoiled

model = Model(inputs=base_model.input, outputs=predictions)

# Compile
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Train
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=valid_generator,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
        tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)
    ]
)

# Save model
model.save('ai_models/mobilenet_model.h5')
print("âœ… Model saved to ai_models/mobilenet_model.h5")
```

**ÄÃ¡nh giÃ¡:**
```python
# Evaluate on test set
test_generator = valid_datagen.flow_from_directory(
    'dataset/test',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {accuracy*100:.2f}%")
```

---

## âš¡ BÆ¯á»šC 4: Tá»‘i Æ¯u Model (Optimization)

### 4.1 Convert sang TensorFlow Lite INT8

**Sá»­ dá»¥ng script cÃ³ sáºµn:**
```bash
python convert_to_tflite.py
```

**Script chi tiáº¿t:**

```python
# convert_to_tflite.py
import tensorflow as tf
import numpy as np
from pathlib import Path

# Load trained model
model = tf.keras.models.load_model('ai_models/mobilenet_model.h5')

# Representative dataset for quantization
def representative_dataset():
    """Generate sample data for INT8 calibration"""
    import cv2
    
    image_dir = Path('dataset/valid/fresh')
    images = list(image_dir.glob('*.jpg'))[:100]  # Use 100 samples
    
    for img_path in images:
        img = cv2.imread(str(img_path))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (224, 224))
        img = img.astype(np.float32) / 255.0
        img = np.expand_dims(img, axis=0)
        yield [img]

# Convert to TFLite with INT8 quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

# Convert
tflite_model = converter.convert()

# Save
output_path = 'ai_models/mobilenet_model_int8.tflite'
with open(output_path, 'wb') as f:
    f.write(tflite_model)

# Check file size
import os
h5_size = os.path.getsize('ai_models/mobilenet_model.h5') / (1024*1024)
tflite_size = os.path.getsize(output_path) / (1024*1024)

print(f"âœ… Conversion complete!")
print(f"ğŸ“¦ Original model (H5): {h5_size:.2f} MB")
print(f"ğŸ“¦ Optimized model (TFLite INT8): {tflite_size:.2f} MB")
print(f"ğŸ¯ Size reduction: {(1 - tflite_size/h5_size)*100:.1f}%")
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- Model gá»‘c (H5): ~10-15 MB
- Model tá»‘i Æ°u (TFLite INT8): ~2-4 MB
- Giáº£m kÃ­ch thÆ°á»›c: ~70-80%
- Äá»™ chÃ­nh xÃ¡c: giáº£m <2% (váº«n >85%)

### 4.2 Tá»‘i Æ¯u YOLOv8

YOLOv8 Ä‘Ã£ nháº¹ rá»“i, nhÆ°ng cÃ³ thá»ƒ export sang ONNX hoáº·c NCNN:

```python
from ultralytics import YOLO

model = YOLO('training/yolo_fruit_detection/weights/best.pt')

# Export to ONNX (faster inference)
model.export(format='onnx')

# Hoáº·c export to NCNN (tá»‘t hÆ¡n cho Pi)
model.export(format='ncnn')
```

---

## ğŸ“¤ BÆ¯á»šC 5: Copy Model Sang Raspberry Pi

### 5.1 Chuáº©n Bá»‹ Files

**TrÃªn Laptop, táº¡o folder Ä‘á»ƒ copy:**
```powershell
# Táº¡o folder models_to_deploy
mkdir models_to_deploy
cd models_to_deploy

# Copy models
copy ..\ai_models\mobilenet_model_int8.tflite .
copy ..\ai_models\yolo_best.pt .

# Copy code
xcopy ..\*.py . /s /e
```

### 5.2 Transfer Files

**PhÆ°Æ¡ng Ã¡n 1: USB Drive**
```powershell
# Copy toÃ n bá»™ folder vÃ o USB
# TrÃªn Pi, mount USB vÃ  copy vÃ o home directory
```

**PhÆ°Æ¡ng Ã¡n 2: SCP (qua máº¡ng)**
```powershell
# TrÃªn laptop (náº¿u cÃ³ SSH)
scp -r models_to_deploy pi@raspberrypi.local:~/System_Conveyor
```

**PhÆ°Æ¡ng Ã¡n 3: Git (khuyáº¿n nghá»‹)**
```bash
# Commit vÃ  push lÃªn GitHub
git add .
git commit -m "Add trained models"
git push origin main

# TrÃªn Pi, pull code
cd ~/System_Conveyor
git pull origin main
```

---

## ğŸ“ BÆ¯á»šC 6: Setup Raspberry Pi 4

### 6.1 CÃ i Äáº·t Há»‡ Äiá»u HÃ nh

1. Download **Raspberry Pi OS (64-bit)** - Bullseye hoáº·c Bookworm
2. Flash vÃ o SD card báº±ng Raspberry Pi Imager
3. Enable SSH vÃ  WiFi trong imager settings
4. Boot Pi vÃ  SSH vÃ o: `ssh pi@raspberrypi.local`

### 6.2 CÃ i Äáº·t Dependencies

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Python packages
sudo apt install -y python3-pip python3-venv
sudo apt install -y python3-opencv python3-numpy
sudo apt install -y python3-picamera2 python3-libcamera

# Install hardware control
sudo apt install -y python3-rpi.gpio python3-gpiozero

# Create virtual environment
cd ~/System_Conveyor
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements-rpi.txt

# Install TFLite Runtime (lightweight)
pip install tflite-runtime
```

### 6.3 Test Models

```bash
# Test MobileNet TFLite
python -c "
import tflite_runtime.interpreter as tflite
interpreter = tflite.Interpreter(model_path='ai_models/mobilenet_model_int8.tflite')
print('âœ… TFLite model loaded successfully!')
"

# Test YOLO
python -c "
from ultralytics import YOLO
model = YOLO('ai_models/yolo_best.pt')
print('âœ… YOLO model loaded successfully!')
"
```

---

## ğŸš€ BÆ¯á»šC 7: Cháº¡y Há»‡ Thá»‘ng TrÃªn Raspberry Pi

### 7.1 Test Hardware

```bash
# Test camera
python hardware/camera.py

# Test servo
python hardware/servo_control.py

# Test motor
python hardware/motor_control.py
```

### 7.2 Cháº¡y Web Interface

```bash
# Start web server
python run_web.py
```

Console sáº½ hiá»ƒn thá»‹:
```
ğŸŒ AI Fruit Sorting System - Web Interface
ğŸ”— Access at: http://raspberrypi.local:5001
```

### 7.3 Truy Cáº­p tá»« Laptop

1. Má»Ÿ browser trÃªn laptop
2. VÃ o `http://raspberrypi.local:5001`
3. Nháº¥n "â–¶ï¸ Start System"
4. Xem camera feed vÃ  phÃ¢n loáº¡i real-time!

---

## ğŸ“Š BÆ¯á»šC 8: ÄÃ¡nh GiÃ¡ Hiá»‡u Suáº¥t (Performance Evaluation)

### 8.1 Cháº¡y Script ÄÃ¡nh GiÃ¡

```bash
python evaluate_system.py
```

Script sáº½ Ä‘o:
- **FPS** (frames per second)
- **Äá»™ chÃ­nh xÃ¡c** (accuracy)
- **Inference time** cho má»—i model
- **CPU/RAM usage**

### 8.2 Káº¿t Quáº£ Mong Äá»£i

| Metric | YOLOv8 | MobileNet INT8 | Combined |
|--------|--------|----------------|----------|
| FPS | 15-20 | 25-30 | 15-25 |
| Accuracy | 90%+ | 85%+ | 85%+ |
| Inference Time | 50-70ms | 30-40ms | 80-110ms |
| RAM Usage | ~800MB | ~200MB | ~1GB |

---

## ğŸ”§ Troubleshooting

### Lá»—i ThÆ°á»ng Gáº·p

**1. TensorFlow GPU khÃ´ng hoáº¡t Ä‘á»™ng trÃªn laptop:**
```bash
# Reinstall TensorFlow with GPU support
pip uninstall tensorflow
pip install tensorflow[and-cuda]
# Hoáº·c install CUDA Toolkit + cuDNN manually
```

**2. Camera khÃ´ng hoáº¡t Ä‘á»™ng trÃªn Pi:**
```bash
# Enable camera
sudo raspi-config
# Interface Options â†’ Camera â†’ Enable

# Test camera
libcamera-hello
```

**3. Model khÃ´ng load Ä‘Æ°á»£c:**
```python
# Check file exists
import os
print(os.path.exists('ai_models/mobilenet_model_int8.tflite'))

# Check file permissions
ls -l ai_models/
```

**4. FPS quÃ¡ tháº¥p trÃªn Pi:**
- Giáº£m resolution áº£nh (640x480 â†’ 320x240)
- TÄƒng `DETECTION_INTERVAL` trong config
- Sá»­ dá»¥ng model nháº¹ hÆ¡n (YOLOv8n thay vÃ¬ YOLOv8s)

---

## ğŸ“š TÃ i Liá»‡u Tham Kháº£o

- **YOLOv8 Documentation**: https://docs.ultralytics.com
- **TensorFlow Lite**: https://www.tensorflow.org/lite
- **Raspberry Pi Camera**: https://www.raspberrypi.com/documentation/computers/camera_software.html
- **Project GitHub**: https://github.com/TruongThiMinhPhuong/System_Conveyor

---

## âœ… Checklist HoÃ n ThÃ nh

- [ ] Chuáº©n bá»‹ mÃ´i trÆ°á»ng laptop (GPU)
- [ ] Thu tháº­p dataset (>500 áº£nh/class)
- [ ] GÃ¡n nhÃ£n dá»¯ liá»‡u
- [ ] Train YOLOv8 (mAP50 >0.8)
- [ ] Train MobileNetV2 (accuracy >85%)
- [ ] Convert sang TFLite INT8
- [ ] Test models trÃªn laptop
- [ ] Setup Raspberry Pi 4
- [ ] Copy models sang Pi
- [ ] Test hardware (camera, servo, motor)
- [ ] Cháº¡y web interface
- [ ] Test há»‡ thá»‘ng hoÃ n chá»‰nh
- [ ] ÄÃ¡nh giÃ¡ FPS vÃ  accuracy

---

**ğŸ‰ ChÃºc báº¡n thÃ nh cÃ´ng vá»›i dá»± Ã¡n phÃ¢n loáº¡i trÃ¡i cÃ¢y tá»± Ä‘á»™ng!**
