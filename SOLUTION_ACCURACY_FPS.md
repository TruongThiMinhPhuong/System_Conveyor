# Giáº£i PhÃ¡p Tá»‘i Æ¯u FPS vÃ  Accuracy - YOLOv8-nano + MobileNetV2

## ğŸ“Š PhÃ¢n TÃ­ch Váº¥n Äá» Hiá»‡n Táº¡i

### Káº¿t Quáº£ ÄÃ¡nh GiÃ¡ (evaluation_20251219_113305.json):
- **FPS hiá»‡n táº¡i: 0.8 FPS** âŒ (Má»¥c tiÃªu: >8-10 FPS)
- **Accuracy: 87.5%** âš ï¸ (VÆ°á»£t 85% nhÆ°ng cÃ³ váº¥n Ä‘á»)
- **YOLO Detection: 1061ms** âŒ (bottleneck chÃ­nh!)
- **Preprocessing: 95ms** âš ï¸
- **Classification: 86ms** âœ…

### Váº¥n Äá» NghiÃªm Trá»ng:
1. **Spoiled Class: 0% precision/recall** - Model khÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c trÃ¡i há»ng!
2. **4/20 áº£nh (20%) failed detection** - YOLO khÃ´ng detect Ä‘Æ°á»£c
3. **Classification confidence tháº¥p: 67.4%** - Model khÃ´ng tá»± tin
4. **YOLO quÃ¡ cháº­m** - Chiáº¿m 85% thá»i gian xá»­ lÃ½
5. **Dataset test chá»‰ cÃ³ fresh** - KhÃ´ng cÃ³ spoiled Ä‘á»ƒ test Ä‘áº§y Ä‘á»§

---

## ğŸ¯ Giáº£i PhÃ¡p ToÃ n Diá»‡n

### 1. Tá»I Æ¯U YOLO DETECTION (Giáº£m tá»« 1061ms â†’ <200ms)

#### A. Giáº£m Input Resolution
```python
# Config hiá»‡n táº¡i: (640, 480) â†’ Äá»•i sang (320, 320)
CAMERA_RESOLUTION = (320, 320)  # Giáº£m 4x pixels
```

#### B. Enable YOLO Optimization Flags
```python
# Trong yolo_detector.py - thÃªm optimization
def detect(self, image, verbose=False):
    results = self.model(
        image,
        conf=self.confidence_threshold,
        iou=self.iou_threshold,
        verbose=verbose,
        half=True,  # FP16 inference (nhanh gáº¥p 2x)
        device='cpu',  # Explicit CPU
        imgsz=320  # Resize input to 320x320
    )
```

#### C. Batch Processing & Async
```python
# Xá»­ lÃ½ nhiá»u frames cÃ¹ng lÃºc (náº¿u cÃ³ queue)
results = self.model(
    [image1, image2, image3],  # Batch inference
    stream=True  # Streaming mode
)
```

### 2. Tá»I Æ¯U PREPROCESSING (Giáº£m tá»« 95ms â†’ <30ms)

#### A. FAST_MODE Configuration
```python
# Trong preprocessing.py
def __init__(self, fast_mode=True):
    if fast_mode:
        self.clahe_tile_size = (2, 2)  # Giáº£m tá»« (4,4) â†’ (2,2)
        self.clahe_clip_limit = 1.5     # Giáº£m tá»« 2.0 â†’ 1.5
        self.apply_blur = False         # Táº¯t blur
        self.enhance_contrast = False    # Táº¯t CLAHE náº¿u khÃ´ng cáº§n
```

#### B. Sá»­ dá»¥ng cv2.resize tá»‘i Æ°u
```python
def resize_image(self, image, size=None):
    # DÃ¹ng INTER_NEAREST cho resize nhanh nháº¥t
    return cv2.resize(image, size, interpolation=cv2.INTER_NEAREST)
```

### 3. Tá»I Æ¯U MOBILENET CLASSIFICATION

#### A. Äáº£m báº£o TFLite Delegate
```python
# CÃ i Ä‘áº·t XNNPACK cho ARM optimization
sudo apt-get install -y libxnnpack-dev

# Trong mobilenet_classifier.py - force XNNPACK
try:
    self.interpreter = tflite.Interpreter(
        model_path=self.model_path,
        num_threads=4  # DÃ¹ng 4 cores
    )
except:
    # Fallback to single thread
    self.interpreter = tflite.Interpreter(model_path=self.model_path)
```

#### B. Quantize Model (INT8)
```python
# Chuyá»ƒn model tá»« FP32 â†’ INT8 (nhanh 4x)
# File: convert_to_int8.py
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.int8]

# Representative dataset
def representative_dataset():
    for i in range(100):
        yield [np.random.rand(1, 224, 224, 3).astype(np.float32)]

converter.representative_dataset = representative_dataset
tflite_model = converter.convert()
```

### 4. Cáº¢I THIá»†N DATA QUALITY (TÄƒng Accuracy lÃªn >95%)

#### A. Thu Tháº­p Dá»¯ Liá»‡u ÄÃºng CÃ¡ch
```bash
# Cáº¦N:
# - 300+ áº£nh fresh (Ä‘a dáº¡ng loáº¡i trÃ¡i, gÃ³c Ä‘á»™, Ã¡nh sÃ¡ng)
# - 300+ áº£nh spoiled (thá»±c sá»± há»ng, thá»‘i, dáº­p nÃ¡t)
# - 100+ áº£nh test fresh
# - 100+ áº£nh test spoiled
```

#### B. Data Augmentation Máº¡nh HÆ¡n
```python
# Trong training script
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.7, 1.3],
    fill_mode='nearest'
)
```

#### C. Class Balancing
```python
# Äáº£m báº£o sá»‘ lÆ°á»£ng áº£nh fresh = spoiled
# Náº¿u thiáº¿u, dÃ¹ng augmentation Ä‘á»ƒ tÄƒng
from imblearn.over_sampling import RandomOverSampler
```

### 5. TRAINING PARAMETERS Tá»I Æ¯U

```python
# Training MobileNetV2
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',  # hoáº·c 'categorical_crossentropy' náº¿u >2 class
    metrics=['accuracy', 'AUC', 'Precision', 'Recall']
)

# Callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5),
    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_accuracy')
]

history = model.fit(
    train_generator,
    epochs=50,  # TÄƒng tá»« 20 â†’ 50
    validation_data=val_generator,
    callbacks=callbacks,
    class_weight={0: 1.0, 1: 1.5}  # Weight cao hÆ¡n cho spoiled class
)
```

### 6. YOLO TRAINING (Náº¿u cáº§n train láº¡i)

```bash
# Train YOLOv8n vá»›i dataset riÃªng
yolo train model=yolov8n.pt data=fruit_data.yaml epochs=100 imgsz=320 \
    batch=32 device=0 patience=20 optimizer=Adam lr0=0.001

# fruit_data.yaml
path: /path/to/dataset
train: images/train
val: images/val
nc: 3  # number of classes
names: ['apple', 'orange', 'guava']
```

---

## ğŸ“‹ Implementation Plan

### BÆ°á»›c 1: Tá»‘i Æ¯u Ngay (Quick Wins)
```python
# utils/config.py - Äá»”I NGAY
CAMERA_RESOLUTION = (320, 320)  # Tá»« (640, 480)
FAST_PREPROCESSING = True
YOLO_CONFIDENCE_THRESHOLD = 0.35  # Giáº£m tá»« 0.5 Ä‘á»ƒ detect nhiá»u hÆ¡n
BLUR_KERNEL_SIZE = 3  # Giáº£m tá»« 5
```

### BÆ°á»›c 2: Tá»‘i Æ¯u Code
- Implement YOLO half precision (FP16)
- Táº¯t CLAHE trong fast mode
- Sá»­ dá»¥ng INTER_NEAREST cho resize
- Enable multi-threading cho TFLite

### BÆ°á»›c 3: Cáº£i Thiá»‡n Data
- Thu tháº­p 200+ áº£nh spoiled thá»±c táº¿
- Augmentation máº¡nh
- Balance dataset
- Táº¡o test set Ä‘áº§y Ä‘á»§

### BÆ°á»›c 4: Retrain Models
- Train MobileNetV2 vá»›i data má»›i (50 epochs)
- Quantize sang INT8
- Validate accuracy >95%

### BÆ°á»›c 5: Final Testing
- Test vá»›i full dataset
- Äáº£m báº£o FPS >8
- Äáº£m báº£o Accuracy >90%
- Äáº£m báº£o Spoiled class cÃ³ F1 >85%

---

## ğŸ¯ Káº¾T QUáº¢ Ká»² Vá»ŒNG

### TrÆ°á»›c Tá»‘i Æ¯u:
- FPS: 0.8 âŒ
- YOLO: 1061ms âŒ
- Preprocessing: 95ms âš ï¸
- Classification: 86ms âœ…
- Accuracy: 87.5% (spoiled = 0%) âŒ

### Sau Tá»‘i Æ¯u:
- FPS: **>8-10** âœ…
- YOLO: **<200ms** âœ… (giáº£m 5x)
- Preprocessing: **<30ms** âœ… (giáº£m 3x)
- Classification: **<50ms** âœ…
- Accuracy: **>95%** âœ…
- Spoiled F1: **>85%** âœ…

---

## ğŸš€ Triá»ƒn Khai Ngay

TÃ´i sáº½ táº¡o cÃ¡c file tá»‘i Æ°u sau:
1. `utils/config_optimized.py` - Configuration tá»‘i Æ°u
2. `ai_models/yolo_detector_optimized.py` - YOLO tá»‘i Æ°u
3. `ai_models/preprocessing_fast.py` - Preprocessing nhanh
4. `training/mobilenet/train_optimized.py` - Training script tá»‘i Æ°u
5. `data_augmentation_pipeline.py` - Pipeline augment data
6. `evaluate_system_fast.py` - Evaluation nhanh

Báº¡n muá»‘n tÃ´i implement ngay khÃ´ng?
